{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giorg\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\giorg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\giorg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk \n",
    "from itertools import chain\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.read_csv(r'C:\\Users\\giorg\\clean_text.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LsiModel\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text']\n",
    "text = list(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['folks', 'paste', 'cytokine', 'storm', 'pfizerbiontech']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "text_words = list(sent_to_words(text))\n",
    "\n",
    "print(text_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['folks', 'paste', 'cytokine', 'storm', 'pfizerbiontech']\n"
     ]
    }
   ],
   "source": [
    "bigram = gensim.models.Phrases(text_words, min_count=1, threshold=10) \n",
    "trigram = gensim.models.Phrases(bigram[text_words], threshold=10)  \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "print(trigram_mod[bigram_mod[text_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['folk', 'paste', 'cytokine', 'storm', 'pfizerbiontech']]\n"
     ]
    }
   ],
   "source": [
    "# Form Bigrams\n",
    "text_words_bigrams = make_bigrams(text_words)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "text_lemmatized = lemmatization(text_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(text_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]]\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(text_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = text_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cytokine'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cytokine', 1),\n",
       "  ('folk', 1),\n",
       "  ('paste', 1),\n",
       "  ('pfizerbiontech', 1),\n",
       "  ('storm', 1)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic LSA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_model = LsiModel(corpus, id2word=id2word, num_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.839*\"vaccine\" + 0.416*\"covid\" + 0.256*\"moderna\" + 0.109*\"dose\" + '\n",
      "  '0.078*\"sputnikv\" + 0.075*\"pfizer\" + 0.074*\"covaxin\" + '\n",
      "  '0.071*\"pfizerbiontech\" + 0.051*\"covidvaccine\" + 0.037*\"india\"'),\n",
      " (1,\n",
      "  '-0.909*\"moderna\" + 0.313*\"vaccine\" + -0.098*\"dose\" + -0.095*\"covidvaccine\" '\n",
      "  '+ -0.094*\"pfizer\" + -0.094*\"shoot\" + 0.085*\"sputnikv\" + -0.078*\"second\" + '\n",
      "  '0.073*\"covaxin\" + -0.070*\"shot\"'),\n",
      " (2,\n",
      "  '0.886*\"covid\" + -0.403*\"vaccine\" + -0.160*\"moderna\" + 0.112*\"covaxin\" + '\n",
      "  '0.073*\"vaccination\" + 0.050*\"covidvaccine\" + -0.039*\"sputnikv\" + 0.038*\"_\" '\n",
      "  '+ 0.021*\"pfizerbiontech\" + 0.021*\"jab\"'),\n",
      " (3,\n",
      "  '-0.939*\"covaxin\" + -0.210*\"dose\" + 0.152*\"covid\" + -0.116*\"india\" + '\n",
      "  '-0.091*\"covishield\" + -0.084*\"covidvaccine\" + 0.057*\"vaccine\" + '\n",
      "  '-0.046*\"amp\" + -0.036*\"ocgn\" + -0.032*\"shoot\"'),\n",
      " (4,\n",
      "  '0.929*\"dose\" + -0.218*\"covaxin\" + 0.157*\"pfizerbiontech\" + '\n",
      "  '0.141*\"covidvaccine\" + -0.140*\"moderna\" + -0.059*\"vaccine\" + -0.057*\"shoot\" '\n",
      "  '+ -0.045*\"pfizer\" + -0.043*\"covid\" + 0.043*\"day\"'),\n",
      " (5,\n",
      "  '-0.952*\"sputnikv\" + -0.144*\"russia\" + 0.116*\"vaccine\" + '\n",
      "  '-0.112*\"covidvaccine\" + -0.112*\"india\" + -0.111*\"russian\" + '\n",
      "  '0.063*\"pfizerbiontech\" + -0.044*\"sputnik\" + -0.042*\"moderna\" + '\n",
      "  '-0.037*\"amp\"'),\n",
      " (6,\n",
      "  '0.855*\"covidvaccine\" + 0.387*\"pfizerbiontech\" + -0.218*\"dose\" + '\n",
      "  '0.150*\"pfizer\" + -0.104*\"moderna\" + -0.077*\"covid\" + -0.075*\"sputnikv\" + '\n",
      "  '0.060*\"astrazeneca\" + 0.057*\"vaccination\" + 0.053*\"shoot\"'),\n",
      " (7,\n",
      "  '0.916*\"pfizer\" + -0.182*\"shoot\" + -0.179*\"covidvaccine\" + 0.172*\"amp\" + '\n",
      "  '0.118*\"astrazeneca\" + -0.108*\"second\" + -0.076*\"day\" + '\n",
      "  '0.064*\"pfizerbiontech\" + -0.061*\"moderna\" + -0.054*\"shot\"'),\n",
      " (8,\n",
      "  '0.652*\"pfizerbiontech\" + -0.400*\"covidvaccine\" + 0.369*\"vaccination\" + '\n",
      "  '0.250*\"day\" + 0.217*\"shoot\" + 0.216*\"second\" + 0.151*\"shot\" + 0.134*\"thank\" '\n",
      "  '+ 0.105*\"amp\" + -0.085*\"sinopharm\"'),\n",
      " (9,\n",
      "  '0.507*\"pfizerbiontech\" + -0.496*\"vaccination\" + -0.342*\"shoot\" + '\n",
      "  '-0.326*\"day\" + -0.213*\"sinopharm\" + -0.209*\"amp\" + -0.203*\"sinovac\" + '\n",
      "  '-0.146*\"second\" + 0.128*\"moderna\" + -0.127*\"pfizer\"'),\n",
      " (10,\n",
      "  '0.719*\"vaccination\" + -0.530*\"shoot\" + -0.253*\"amp\" + -0.180*\"second\" + '\n",
      "  '-0.147*\"day\" + -0.133*\"shot\" + -0.133*\"pfizer\" + 0.105*\"moderna\" + '\n",
      "  '0.097*\"india\" + -0.053*\"first\"'),\n",
      " (11,\n",
      "  '0.834*\"amp\" + 0.362*\"india\" + -0.247*\"shoot\" + -0.229*\"pfizer\" + '\n",
      "  '-0.133*\"second\" + -0.078*\"covaxin\" + 0.073*\"pfizerbiontech\" + '\n",
      "  '-0.073*\"sputnikv\" + -0.065*\"shot\" + 0.053*\"moderna\"'),\n",
      " (12,\n",
      "  '0.879*\"india\" + -0.324*\"amp\" + 0.148*\"shoot\" + -0.138*\"sinovac\" + '\n",
      "  '-0.137*\"sinopharm\" + -0.103*\"covaxin\" + -0.089*\"sputnikv\" + 0.083*\"pfizer\" '\n",
      "  '+ -0.080*\"vaccination\" + 0.070*\"second\"'),\n",
      " (13,\n",
      "  '-0.813*\"day\" + 0.489*\"shoot\" + 0.210*\"vaccination\" + -0.132*\"jab\" + '\n",
      "  '0.094*\"amp\" + 0.085*\"thank\" + -0.068*\"shot\" + -0.053*\"good\" + 0.047*\"dose\" '\n",
      "  '+ 0.033*\"st\"'),\n",
      " (14,\n",
      "  '-0.598*\"second\" + -0.484*\"shot\" + 0.335*\"shoot\" + 0.316*\"day\" + '\n",
      "  '-0.256*\"sinovac\" + -0.200*\"sinopharm\" + -0.194*\"jab\" + -0.143*\"china\" + '\n",
      "  '-0.086*\"india\" + -0.072*\"week\"'),\n",
      " (15,\n",
      "  '0.661*\"sinovac\" + 0.372*\"sinopharm\" + -0.317*\"second\" + 0.251*\"china\" + '\n",
      "  '0.242*\"pfizerbiontech\" + -0.215*\"shot\" + -0.147*\"amp\" + 0.140*\"thank\" + '\n",
      "  '0.126*\"india\" + 0.116*\"chinese\"'),\n",
      " (16,\n",
      "  '0.693*\"sinopharm\" + -0.604*\"sinovac\" + 0.226*\"first\" + 0.209*\"jab\" + '\n",
      "  '0.138*\"thank\" + 0.127*\"china\" + -0.088*\"second\" + -0.035*\"amp\" + '\n",
      "  '0.033*\"uae\" + 0.032*\"pakistan\"'),\n",
      " (17,\n",
      "  '-0.952*\"thank\" + 0.162*\"pfizerbiontech\" + 0.125*\"sinopharm\" + '\n",
      "  '0.088*\"astrazeneca\" + 0.081*\"jab\" + 0.079*\"coronavirus\" + 0.074*\"shoot\" + '\n",
      "  '-0.047*\"shot\" + 0.047*\"first\" + 0.043*\"vaccination\"'),\n",
      " (18,\n",
      "  '-0.667*\"first\" + -0.559*\"jab\" + 0.328*\"sinopharm\" + -0.165*\"astrazeneca\" + '\n",
      "  '0.149*\"second\" + 0.148*\"china\" + 0.126*\"pfizerbiontech\" + 0.089*\"day\" + '\n",
      "  '-0.085*\"coronavirus\" + -0.065*\"sinovac\"'),\n",
      " (19,\n",
      "  '-0.846*\"coronavirus\" + -0.368*\"astrazeneca\" + -0.200*\"shot\" + 0.152*\"jab\" + '\n",
      "  '0.115*\"first\" + 0.114*\"side_effect\" + 0.077*\"pfizerbiontech\" + '\n",
      "  '-0.075*\"case\" + 0.069*\"second\" + -0.066*\"thank\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(lsa_model.print_topics())\n",
    "doc_lda = lsa_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.2812645704816641\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "#print('\\nPerplexity: ', lsa_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lsa = CoherenceModel(model=lsa_model, texts=text_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lsa = coherence_model_lsa.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(lsa_model.top_topics(corpus,topn=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LsiModel' object has no attribute 'inference'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-d5343683277b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlsa_visualization\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlsa_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlsa_visualization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\gensim.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvis_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\gensim.py\u001b[0m in \u001b[0;36m_extract_data\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dists)\u001b[0m\n\u001b[0;32m     46\u001b[0m           \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m           \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m       \u001b[0mdoc_topic_dists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LsiModel' object has no attribute 'inference'"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "lsa_visualization = pyLDAvis.gensim.prepare(lsa_model, corpus, id2word)\n",
    "pyLDAvis.display(lsa_visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to find ideal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
